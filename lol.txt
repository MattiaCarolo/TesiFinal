{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import torch\n",
    "import hashlib\n",
    "import itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "from progress.bar import Bar\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from Utils.NotesSeq import NoteSeq as ns\n",
    "from Utils.EventSeq import EventSeq as es\n",
    "from Utils.ControlSeq import ControlSeq as cs\n",
    "from Utils import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Gumbel\n",
    "from torch import optim\n",
    "\n",
    "from config import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretty_midi import PrettyMIDI, Note, Instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_path = 'save/train.sess'\n",
    "data_path = 'Processed-RAW'\n",
    "saving_interval = 60.\n",
    "reset_optimizer = False\n",
    "enable_logging = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root, verbose=False):\n",
    "        assert os.path.isdir(root), root\n",
    "        paths = utils.find_files_by_extensions(root, ['.data'])\n",
    "\n",
    "        self.root = root\n",
    "        self.samples = []\n",
    "        self.seqlens = []\n",
    "        self.samples2 = []\n",
    "        self.seqlens2 = []\n",
    "\n",
    "        if verbose:\n",
    "            paths = Bar(root).iter(list(paths))\n",
    "        for path in paths:\n",
    "            eventseq, eventseq2, controlseq, controlseq2 = torch.load(path)\n",
    "            controlseq = cs.recover_compressed_array(controlseq)\n",
    "            controlseq2 = cs.recover_compressed_array(controlseq2)\n",
    "            assert len(eventseq) == len(controlseq)\n",
    "            assert len(eventseq2) == len(controlseq2)\n",
    "            self.samples.append((eventseq, controlseq))\n",
    "            self.seqlens.append(len(eventseq))\n",
    "            self.samples2.append((eventseq2,controlseq2))\n",
    "            self.seqlens2.append(len(eventseq2))\n",
    "\n",
    "        self.avglen = np.mean(self.seqlens)\n",
    "        self.avglen2 = np.mean(self.seqlens2)\n",
    "    \n",
    "    def batches(self, batch_size, window_size, stride_size):\n",
    "        indeces = [(i, range(j, j + window_size))\n",
    "                   for i, seqlen in enumerate(self.seqlens)\n",
    "                   for j in range(0, seqlen - window_size, stride_size)]\n",
    "        while True:\n",
    "            eventseq_batch = []\n",
    "            controlseq_batch = []\n",
    "            eventseq_batch2 = []\n",
    "            controlseq_batch2 = []\n",
    "            n = 0\n",
    "            for ii in np.random.permutation(len(indeces)):\n",
    "                i, r = indeces[ii]\n",
    "\n",
    "                eventseq, controlseq = self.samples[i]\n",
    "                eventseq2, controlseq2 = self.samples2[i]\n",
    "\n",
    "                eventseq = eventseq[r.start:r.stop]\n",
    "                eventseq2 = eventseq2[r.start:r.stop]\n",
    "\n",
    "                controlseq = controlseq[r.start:r.stop]\n",
    "                controlseq2 = controlseq2[r.start:r.stop]\n",
    "\n",
    "                eventseq_batch.append(eventseq)\n",
    "                controlseq_batch.append(controlseq)\n",
    "                eventseq_batch2.append(eventseq2)\n",
    "                controlseq_batch2.append(controlseq2)\n",
    "\n",
    "                n += 1\n",
    "                if n == batch_size:\n",
    "                    yield (np.stack(eventseq_batch, axis=1),\n",
    "                           np.stack(controlseq_batch, axis=1),\n",
    "                           np.stack(eventseq_batch, axis=1),\n",
    "                           np.stack(controlseq_batch, axis=1))\n",
    "                    eventseq_batch.clear()\n",
    "                    controlseq_batch.clear()\n",
    "                    eventseq_batch2.clear()\n",
    "                    controlseq_batch2.clear()\n",
    "                    n = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f'Dataset(root=\"{self.root}\", '\n",
    "                f'samples={len(self.samples)}, '\n",
    "                f'avglen={self.avglen})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(data_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset.samples)\n",
    "assert dataset_size > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2X(nn.Module):\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.event_embedding.weight)\n",
    "        nn.init.xavier_normal_(self.inithid_fc.weight)\n",
    "        self.inithid_fc.bias.data.fill_(0.)\n",
    "        nn.init.xavier_normal_(self.concat_input_fc.weight)\n",
    "        nn.init.xavier_normal_(self.output_fc.weight)\n",
    "        self.output_fc.bias.data.fill_(0.)\n",
    "\n",
    "    def __init__(self, event_dim, control_dim, init_dim, hidden_dim,\n",
    "                 inithid_fc = None, gru_layers=3, gru_dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters initialization\n",
    "        self.event_dim = event_dim\n",
    "        self.control_dim = control_dim\n",
    "        self.init_dim = init_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_layers = gru_layers\n",
    "        self.concat_dim = event_dim + 1 + control_dim\n",
    "        self.input_dim = hidden_dim\n",
    "        self.output_dim = event_dim\n",
    "\n",
    "        self.primary_event = self.event_dim - 1\n",
    "\n",
    "        #Model Layers\n",
    "\n",
    "        self.inithid_fc = nn.Linear(init_dim, gru_layers * hidden_dim)\n",
    "        self.inithid_fc_activation = nn.Tanh()\n",
    "\n",
    "        self.event_embedding = nn.Embedding(event_dim, event_dim)\n",
    "        self.concat_input_fc = nn.Linear(self.concat_dim, self.input_dim)\n",
    "        self.concat_input_fc_activation = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_dim,\n",
    "                          num_layers=gru_layers, dropout=gru_dropout)\n",
    "        self.output_fc = nn.Linear(hidden_dim * gru_layers, self.output_dim)\n",
    "        self.output_fc_activation = nn.Softmax(dim=-1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, event, control=None, hidden=None):\n",
    "        # One step forward\n",
    "\n",
    "        assert len(event.shape) == 2\n",
    "        assert event.shape[0] == 1\n",
    "        batch_size = event.shape[1]\n",
    "        event = self.event_embedding(event)\n",
    "\n",
    "        if control is None:\n",
    "            default = torch.ones(1, batch_size, 1).to(device)\n",
    "            control = torch.zeros(1, batch_size, self.control_dim).to(device)\n",
    "        else:\n",
    "            default = torch.zeros(1, batch_size, 1).to(device)\n",
    "            assert control.shape == (1, batch_size, self.control_dim)\n",
    "\n",
    "        concat = torch.cat([event, default, control], -1)\n",
    "        input = self.concat_input_fc(concat)  #nn.Linear(self.concat_dim, self.input_dim)\n",
    "        input = self.concat_input_fc_activation(input)  #nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "        _, hidden = self.gru(input, hidden)  #nn.GRU(self.input_dim, self.hidden_dim,num_layers=gru_layers, dropout=gru_dropout)\n",
    "\n",
    "        output = hidden.permute(1, 0, 2).contiguous()\n",
    "        output = output.view(batch_size, -1).unsqueeze(0)\n",
    "        output = self.output_fc(output) #nn.Linear(hidden_dim * gru_layers, self.output_dim)\n",
    "        return output, hidden # output is under the form of a logit\n",
    "    \n",
    "    def _sample_event(self, output, greedy=True, temperature=1.0):\n",
    "        if greedy:\n",
    "            return output.argmax(-1)\n",
    "        else:\n",
    "            output = output / temperature\n",
    "            probs = self.output_fc_activation(output)\n",
    "            return Categorical(probs).sample()\n",
    "    \n",
    "    def get_primary_event(self, batch_size):\n",
    "        return torch.LongTensor([[self.primary_event] * batch_size]).to(device)\n",
    "\n",
    "    def init_to_hidden(self, init):\n",
    "        # [batch_size, init_dim]\n",
    "        batch_size = init.shape[0]\n",
    "        out = self.inithid_fc(init)\n",
    "        out = self.inithid_fc_activation(out)\n",
    "        out = out.view(self.gru_layers, batch_size, self.hidden_dim)\n",
    "        return out\n",
    "    \n",
    "    def expand_controls(self, controls, steps):\n",
    "        # [1 or steps, batch_size, control_dim]\n",
    "        assert len(controls.shape) == 3\n",
    "        assert controls.shape[2] == self.control_dim\n",
    "        if controls.shape[0] > 1:\n",
    "            assert controls.shape[0] >= steps\n",
    "            return controls[:steps]\n",
    "        return controls.repeat(steps, 1, 1)\n",
    "    \n",
    "    def generate(self, init, batch_size, init_dim, steps, events = None, controls = None,\n",
    "                 verbose = True, greedy = 1.0, temperature = 1.0):\n",
    "        batch_size = batch_size\n",
    "        self.init_dim = init_dim\n",
    "\n",
    "        assert init.shape[1] == self.init_dim\n",
    "        assert steps > 0\n",
    "\n",
    "        use_teacher_forcing = events is not None\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            assert len(events.shape) == 2\n",
    "            assert events.shape[0] >= steps - 1\n",
    "            events = events[:steps-1]\n",
    "\n",
    "        event = self.get_primary_event(batch_size)\n",
    "\n",
    "        use_control = controls is not None\n",
    "\n",
    "        if use_control:\n",
    "            controls = self.expand_controls(controls, steps)\n",
    "        hidden = self.init_to_hidden(init)\n",
    "\n",
    "        outputs = []\n",
    "        step_iter = range(steps)\n",
    "\n",
    "        if verbose:\n",
    "            step_iter = Bar('Generating').iter(step_iter)\n",
    "\n",
    "        for step in step_iter:\n",
    "            #control = controls[step].unsqueeze(0) if use_control else None\n",
    "            control = None\n",
    "            output, hidden = self.forward(event, control, hidden)\n",
    "\n",
    "            use_greedy = np.random.random() < greedy\n",
    "            event = self._sample_event(output, greedy=use_greedy,\n",
    "                                       temperature=temperature)\n",
    "            \n",
    "            #here outputs are served in the lo-git format\n",
    "            outputs.append(output)\n",
    "            #\n",
    "            #if use_teacher_forcing and step < steps - 1: # avoid last one\n",
    "            #    if np.random.random() <= teacher_forcing_ratio:\n",
    "            #        event = events[step].unsqueeze(0)\n",
    "        \n",
    "        return torch.cat(outputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2XSecondary(nn.Module):\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.event_embedding.weight)\n",
    "        nn.init.xavier_normal_(self.inithid_fc.weight)\n",
    "        self.inithid_fc.bias.data.fill_(0.)\n",
    "        nn.init.xavier_normal_(self.concat_input_fc.weight)\n",
    "        nn.init.xavier_normal_(self.output_fc.weight)\n",
    "        self.output_fc.bias.data.fill_(0.)\n",
    "\n",
    "    def __init__(self, event_dim, control_dim, init_dim, hidden_dim,\n",
    "                 inithid_fc = None, gru_layers=3, gru_dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters initialization\n",
    "        self.event_dim = event_dim\n",
    "        self.control_dim = control_dim\n",
    "        self.init_dim = init_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_layers = gru_layers\n",
    "        self.concat_dim = event_dim + event_dim + 1 + control_dim\n",
    "        self.input_dim = hidden_dim\n",
    "        self.output_dim = event_dim\n",
    "\n",
    "        self.primary_event = self.event_dim - 1\n",
    "\n",
    "        #Model Layers\n",
    "\n",
    "        self.inithid_fc = nn.Linear(init_dim, gru_layers * hidden_dim)\n",
    "        self.inithid_fc_activation = nn.Tanh()\n",
    "\n",
    "        self.event_embedding = nn.Embedding(event_dim, event_dim)\n",
    "        self.concat_input_fc = nn.Linear(self.concat_dim, self.input_dim)\n",
    "        self.concat_input_fc_activation = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_dim,\n",
    "                          num_layers=gru_layers, dropout=gru_dropout)\n",
    "        self.output_fc = nn.Linear(hidden_dim * gru_layers, self.output_dim)\n",
    "        self.output_fc_activation = nn.Softmax(dim=-1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, event, event2, control=None, hidden=None):\n",
    "        # One step forward\n",
    "\n",
    "        assert len(event.shape) == 2\n",
    "        assert event.shape[0] == 1\n",
    "        batch_size = event.shape[1]\n",
    "        event = self.event_embedding(event)\n",
    "\n",
    "        #print(event2.shape)\n",
    "        if(len(event2.shape) <= 2):\n",
    "            event2 = torch.tensor(event2).to(device).long()\n",
    "            event2 = self.event_embedding(event2)\n",
    "\n",
    "        \"\"\"\n",
    "        print(event2.shape)\n",
    "        print(event.shape)\n",
    "        print(len(event.shape))\n",
    "        \"\"\"\n",
    "\n",
    "        if control is None:\n",
    "            default = torch.ones(1, batch_size, 1).to(device)\n",
    "            control = torch.zeros(1, batch_size, self.control_dim).to(device)\n",
    "        else:\n",
    "            default = torch.zeros(1, batch_size, 1).to(device)\n",
    "            assert control.shape == (1, batch_size, self.control_dim)\n",
    "\n",
    "        event = torch.cat([event,event2],-1)\n",
    "        concat = torch.cat([event, default, control], -1)\n",
    "        input = self.concat_input_fc(concat)  #nn.Linear(self.concat_dim, self.input_dim)\n",
    "        input = self.concat_input_fc_activation(input)  #nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "        _, hidden = self.gru(input, hidden)  #nn.GRU(self.input_dim, self.hidden_dim,num_layers=gru_layers, dropout=gru_dropout)\n",
    "\n",
    "        output = hidden.permute(1, 0, 2).contiguous()\n",
    "        output = output.view(batch_size, -1).unsqueeze(0)\n",
    "        output = self.output_fc(output) #nn.Linear(hidden_dim * gru_layers, self.output_dim)\n",
    "\n",
    "        #print(\"prima passata\")\n",
    "\n",
    "        return output, hidden # output is under the form of a logit\n",
    "    \n",
    "    def _sample_event(self, output, greedy=True, temperature=1.0):\n",
    "        if greedy:\n",
    "            return output.argmax(-1)\n",
    "        else:\n",
    "            output = output / temperature\n",
    "            probs = self.output_fc_activation(output)\n",
    "            return Categorical(probs).sample()\n",
    "    \n",
    "    def get_primary_event(self, batch_size):\n",
    "        return torch.LongTensor([[self.primary_event] * batch_size]).to(device)\n",
    "\n",
    "    def init_to_hidden(self, init):\n",
    "        # [batch_size, init_dim]\n",
    "        batch_size = init.shape[0]\n",
    "        out = self.inithid_fc(init)\n",
    "        out = self.inithid_fc_activation(out)\n",
    "        out = out.view(self.gru_layers, batch_size, self.hidden_dim)\n",
    "        return out\n",
    "    \n",
    "    def expand_controls(self, controls, steps):\n",
    "        # [1 or steps, batch_size, control_dim]\n",
    "        assert len(controls.shape) == 3\n",
    "        assert controls.shape[2] == self.control_dim\n",
    "        if controls.shape[0] > 1:\n",
    "            assert controls.shape[0] >= steps\n",
    "            return controls[:steps]\n",
    "        return controls.repeat(steps, 1, 1)\n",
    "    \n",
    "    def generate(self, init, batch_size, init_dim, steps, events = None, controls = None, events2 = None,\n",
    "                 verbose = True, greedy = 1.0, temperature = 1.0, teacher_forcing_ratio = 1.0):\n",
    "        batch_size = batch_size\n",
    "        self.init_dim = init_dim\n",
    "\n",
    "        assert init.shape[1] == self.init_dim\n",
    "        assert steps > 0\n",
    "\n",
    "        use_teacher_forcing = events is not None\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            assert len(events.shape) == 2\n",
    "            assert events.shape[0] >= steps - 1\n",
    "            events = events[:steps-1]\n",
    "\n",
    "        event = self.get_primary_event(batch_size)\n",
    "        event2 = self.get_primary_event(batch_size)\n",
    "\n",
    "        use_control = controls is not None\n",
    "\n",
    "        if use_control:\n",
    "            controls = self.expand_controls(controls, steps)\n",
    "        hidden = self.init_to_hidden(init)\n",
    "\n",
    "        outputs = []\n",
    "        step_iter = range(steps)\n",
    "\n",
    "        if verbose:\n",
    "            step_iter = Bar('Generating').iter(step_iter)\n",
    "\n",
    "        for step in step_iter:\n",
    "            #control = controls[step].unsqueeze(0) if use_control else None\n",
    "            control = None\n",
    "            output, _ = self.forward(event, event2, control, hidden)\n",
    "\n",
    "            use_greedy = np.random.random() < greedy\n",
    "            event = self._sample_event(output, greedy=use_greedy,\n",
    "                                       temperature=temperature)\n",
    "            \n",
    "            #here outputs are served in the logit format\n",
    "            outputs.append(output)\n",
    "            #\n",
    "            if use_teacher_forcing and step < steps - 1: # avoid last one\n",
    "                if np.random.random() <= teacher_forcing_ratio:\n",
    "                    event = events[step].unsqueeze(0)\n",
    "                    event2 = events2[step].unsqueeze(0)\n",
    "        \n",
    "        outputs = torch.cat(outputs, 0)\n",
    "\n",
    "        return outputs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for training process\n",
    "\n",
    "init_dim = 32\n",
    "event_dim = es.dim()\n",
    "control_dim = cs.dim()\n",
    "hidden_dim = 512\n",
    "gru_layers = 3\n",
    "gru_droput = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "window_size = 200\n",
    "stride_size = 10\n",
    "use_transposition = False\n",
    "control_ratio = 1.0\n",
    "teacher_forcing_ratio = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'init_dim': init_dim,\n",
    "    'event_dim': event_dim,\n",
    "    'control_dim': control_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'gru_layers': gru_layers,\n",
    "    'gru_dropout': gru_droput,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = torch.randn(batch_size, init_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = P2X(**model_config).to(device)\n",
    "model2 = P2XSecondary(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters()) + list(model.parameters())\n",
    "paramsB = list(model.parameters()) + list(model2.parameters())\n",
    "\n",
    "optimizer = optim.Adam(paramsB, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adagrad(paramsB, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 10.971273422241211\n",
      "iter 1, loss: 10.77971076965332\n",
      "iter 2, loss: 10.322685241699219\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     controls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     43\u001b[0m init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, model2\u001b[38;5;241m.\u001b[39minit_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 44\u001b[0m outputsB \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meventsB\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m outputsB\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m eventsB\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#eventsF = torch.cat((events,eventsB))\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#outputsF = torch.cat((outputs, outputsB),2)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#print(outputsF)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 145\u001b[0m, in \u001b[0;36mP2XSecondary.generate\u001b[0;34m(self, init, batch_size, init_dim, steps, events, controls, events2, verbose, greedy, temperature, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m step_iter:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m#control = controls[step].unsqueeze(0) if use_control else None\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     control \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     use_greedy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m greedy\n\u001b[1;32m    148\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_event(output, greedy\u001b[38;5;241m=\u001b[39muse_greedy,\n\u001b[1;32m    149\u001b[0m                                temperature\u001b[38;5;241m=\u001b[39mtemperature)\n",
      "Cell \u001b[0;32mIn[9], line 74\u001b[0m, in \u001b[0;36mP2XSecondary.forward\u001b[0;34m(self, event, event2, control, hidden)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_input_fc(concat)  \u001b[38;5;66;03m#nn.Linear(self.concat_dim, self.input_dim)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_input_fc_activation(\u001b[38;5;28minput\u001b[39m)  \u001b[38;5;66;03m#nn.LeakyReLU(0.1, inplace=True)\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m _, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#nn.GRU(self.input_dim, self.hidden_dim,num_layers=gru_layers, dropout=gru_dropout)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m output \u001b[38;5;241m=\u001b[39m hidden\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     77\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1133\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1137\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#try:\n",
    "batch_gen = dataset.batches(batch_size, window_size, stride_size)\n",
    "for iteration, data in enumerate(batch_gen):\n",
    "    e1 = data[0]\n",
    "    c1 = data[1]\n",
    "    e2 = data[2]\n",
    "    c2 = data[3]\n",
    "\n",
    "    # First Model process\n",
    "\n",
    "    events = torch.LongTensor(e1).to(device)\n",
    "    assert events.shape[0] == window_size\n",
    "    assert len(events.shape) == 2\n",
    "    assert events.shape[0] >= window_size - 1\n",
    "\n",
    "    if np.random.random() < control_ratio:\n",
    "        controls = torch.FloatTensor(c1).to(device)\n",
    "        assert controls.shape[0] == window_size\n",
    "    else:\n",
    "        controls = None\n",
    "\n",
    "    init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "    outputs = model.generate(init,batch_size, model.init_dim, window_size, \n",
    "                            events[:-1], controls)\n",
    "    \n",
    "    assert outputs.shape[:2] == events.shape[:2]\n",
    "    loss = loss_function(outputs.view(-1, event_dim), events.view(-1))\n",
    "    #print(outputs)\n",
    "\n",
    "    # Second Model process\n",
    "\n",
    "    eventsB = torch.LongTensor(e2).to(device)\n",
    "    assert eventsB.shape[0] == window_size\n",
    "    assert len(eventsB.shape) == 2\n",
    "    assert eventsB.shape[0] >= window_size - 1\n",
    "\n",
    "    if np.random.random() < control_ratio:\n",
    "        controls = torch.FloatTensor(c2).to(device)\n",
    "        assert controls.shape[0] == window_size\n",
    "    else:\n",
    "        controls = None\n",
    "\n",
    "    init = torch.randn(batch_size, model2.init_dim).to(device)\n",
    "    outputsB = model2.generate(init,batch_size, model2.init_dim, window_size, \n",
    "                            events=eventsB[:-1], events2=outputs[:-1], controls=controls)\n",
    "    \n",
    "    assert outputsB.shape[:2] == eventsB.shape[:2]\n",
    "    #eventsF = torch.cat((events,eventsB))\n",
    "    #outputsF = torch.cat((outputs, outputsB),2)\n",
    "    #print(outputsF)\n",
    "\n",
    "    loss = loss + loss_function(outputsB.view(-1, event_dim), eventsB.view(-1))\n",
    "\n",
    "    model.zero_grad()\n",
    "    model2.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    #concatenated_vectors = torch.cat((outputs, outputsB),2)\n",
    "    #print(outputsF.shape)\n",
    "    #print(outputsB.shape)\n",
    "    #print(events.shape)\n",
    "\n",
    "    norm = utils.compute_gradient_norm(model.parameters())\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'iter {iteration}, loss: {loss.item()}')\n",
    "\n",
    "    \n",
    "\n",
    "#except:\n",
    "#    print(\"banane\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bagigi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
