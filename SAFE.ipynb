{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import torch\n",
    "import hashlib\n",
    "import itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "from progress.bar import Bar\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from Utils.NotesSeq import NoteSeq as ns\n",
    "from Utils.EventSeq import EventSeq as es\n",
    "from Utils.ControlSeq import ControlSeq as cs\n",
    "from Utils import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Gumbel\n",
    "from torch import optim\n",
    "\n",
    "from config import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretty_midi import PrettyMIDI, Note, Instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_path = 'save/train.sess'\n",
    "data_path = 'Processed-RAW'\n",
    "saving_interval = 60.\n",
    "reset_optimizer = False\n",
    "enable_logging = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root, verbose=False):\n",
    "        assert os.path.isdir(root), root\n",
    "        paths = utils.find_files_by_extensions(root, ['.data'])\n",
    "\n",
    "        self.root = root\n",
    "        self.samples = []\n",
    "        self.seqlens = []\n",
    "        self.samples2 = []\n",
    "        self.seqlens2 = []\n",
    "\n",
    "        if verbose:\n",
    "            paths = Bar(root).iter(list(paths))\n",
    "        for path in paths:\n",
    "            eventseq, eventseq2, controlseq, controlseq2 = torch.load(path)\n",
    "            controlseq = cs.recover_compressed_array(controlseq)\n",
    "            controlseq2 = cs.recover_compressed_array(controlseq2)\n",
    "            assert len(eventseq) == len(controlseq)\n",
    "            assert len(eventseq2) == len(controlseq2)\n",
    "            self.samples.append((eventseq, controlseq))\n",
    "            self.seqlens.append(len(eventseq))\n",
    "            self.samples2.append((eventseq2,controlseq2))\n",
    "            self.seqlens2.append(len(eventseq2))\n",
    "\n",
    "        self.avglen = np.mean(self.seqlens)\n",
    "        self.avglen2 = np.mean(self.seqlens2)\n",
    "    \n",
    "    def batches(self, batch_size, window_size, stride_size):\n",
    "        indeces = [(i, range(j, j + window_size))\n",
    "                   for i, seqlen in enumerate(self.seqlens)\n",
    "                   for j in range(0, seqlen - window_size, stride_size)]\n",
    "        while True:\n",
    "            eventseq_batch = []\n",
    "            controlseq_batch = []\n",
    "            eventseq_batch2 = []\n",
    "            controlseq_batch2 = []\n",
    "            n = 0\n",
    "            for ii in np.random.permutation(len(indeces)):\n",
    "                i, r = indeces[ii]\n",
    "\n",
    "                eventseq, controlseq = self.samples[i]\n",
    "                eventseq2, controlseq2 = self.samples2[i]\n",
    "\n",
    "                eventseq = eventseq[r.start:r.stop]\n",
    "                eventseq2 = eventseq2[r.start:r.stop]\n",
    "\n",
    "                controlseq = controlseq[r.start:r.stop]\n",
    "                controlseq2 = controlseq2[r.start:r.stop]\n",
    "\n",
    "                eventseq_batch.append(eventseq)\n",
    "                controlseq_batch.append(controlseq)\n",
    "                eventseq_batch2.append(eventseq2)\n",
    "                controlseq_batch2.append(controlseq2)\n",
    "\n",
    "                n += 1\n",
    "                if n == batch_size:\n",
    "                    yield (np.stack(eventseq_batch, axis=1),\n",
    "                           np.stack(controlseq_batch, axis=1),\n",
    "                           np.stack(eventseq_batch, axis=1),\n",
    "                           np.stack(controlseq_batch, axis=1))\n",
    "                    eventseq_batch.clear()\n",
    "                    controlseq_batch.clear()\n",
    "                    eventseq_batch2.clear()\n",
    "                    controlseq_batch2.clear()\n",
    "                    n = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f'Dataset(root=\"{self.root}\", '\n",
    "                f'samples={len(self.samples)}, '\n",
    "                f'avglen={self.avglen})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(data_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset.samples)\n",
    "assert dataset_size > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for training process\n",
    "\n",
    "init_dim = 32\n",
    "event_dim = es.dim()\n",
    "control_dim = cs.dim()\n",
    "hidden_dim = 512\n",
    "gru_layers = 3\n",
    "gru_droput = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "window_size = 200\n",
    "stride_size = 10\n",
    "use_transposition = False\n",
    "control_ratio = 1.0\n",
    "teacher_forcing_ratio = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'init_dim': init_dim,\n",
    "    'event_dim': event_dim,\n",
    "    'control_dim': control_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'gru_layers': gru_layers,\n",
    "    'gru_dropout': gru_droput,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = torch.randn(batch_size, init_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PerformanceRNN\n",
    "\n",
    "model = PerformanceRNN(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters()) + list(model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, model_config, sess_path):\n",
    "    print('Saving to', sess_path)\n",
    "    torch.save({'model_config': model_config,\n",
    "                'model_state': model.state_dict(),\n",
    "                'model_optimizer_state': optimizer.state_dict()}, sess_path)\n",
    "    print('Done saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 21:41:26,887 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2024-08-12 21:41:27,208 - DEBUG - Creating converter from 7 to 5\n",
      "2024-08-12 21:41:27,208 - DEBUG - Creating converter from 5 to 7\n",
      "2024-08-12 21:41:27,209 - DEBUG - Creating converter from 7 to 5\n",
      "2024-08-12 21:41:27,209 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "if enable_logging:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to save/tempA.sess\n",
      "Done saving\n",
      "iter 0, loss: 5.477005481719971\n",
      "iter 1, loss: 5.209493637084961\n",
      "iter 2, loss: 6.461246490478516\n",
      "iter 3, loss: 5.502777099609375\n",
      "iter 4, loss: 4.967595100402832\n",
      "Saving to save/tempA.sess\n",
      "Done saving\n",
      "iter 5, loss: 5.046258926391602\n",
      "iter 6, loss: 4.907918930053711\n",
      "iter 7, loss: 4.843714714050293\n",
      "iter 8, loss: 4.799515247344971\n",
      "iter 9, loss: 4.772924423217773\n",
      "Saving to save/tempA.sess\n",
      "Done saving\n",
      "iter 10, loss: 4.765472888946533\n",
      "iter 11, loss: 4.662515163421631\n",
      "iter 12, loss: 4.6570515632629395\n",
      "iter 13, loss: 4.678713321685791\n",
      "iter 14, loss: 4.595309257507324\n",
      "Saving to save/tempA.sess\n",
      "Done saving\n",
      "iter 15, loss: 4.534029006958008\n",
      "iter 16, loss: 4.724520683288574\n",
      "iter 17, loss: 4.654621124267578\n",
      "iter 18, loss: 4.524623394012451\n",
      "iter 19, loss: 4.5000529289245605\n",
      "Saving to save/tempA.sess\n",
      "Done saving\n",
      "iter 20, loss: 4.362791538238525\n",
      "iter 21, loss: 4.4422454833984375\n",
      "iter 22, loss: 4.332684516906738\n",
      "iter 23, loss: 4.154935836791992\n",
      "iter 24, loss: 4.0732951164245605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#concatenated_vectors = torch.cat((outputs, outputsB),2)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#print(outputsF.shape)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#print(outputsB.shape)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#print(events.shape)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m norm \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcompute_gradient_norm(model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/envs/Music/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_gen = dataset.batches(batch_size, window_size, stride_size)\n",
    "for iteration, data in enumerate(batch_gen):\n",
    "    e1 = data[0]\n",
    "    c1 = data[1]\n",
    "\n",
    "    # First Model process\n",
    "\n",
    "    events = torch.LongTensor(e1).to(device)\n",
    "    assert events.shape[0] == window_size\n",
    "    assert len(events.shape) == 2\n",
    "    assert events.shape[0] >= window_size - 1\n",
    "\n",
    "    if np.random.random() < control_ratio:\n",
    "        controls = torch.FloatTensor(c1).to(device)\n",
    "        assert controls.shape[0] == window_size\n",
    "    else:\n",
    "        controls = None\n",
    "\n",
    "    init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "    outputs = model.generate(init, window_size, \n",
    "                            events[:-1], controls,output_type = 'logit')\n",
    "    \n",
    "    assert outputs.shape[:2] == events.shape[:2]\n",
    "    loss = loss_function(outputs.view(-1, event_dim), events.view(-1))\n",
    "    #print(outputs)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    #concatenated_vectors = torch.cat((outputs, outputsB),2)\n",
    "    #print(outputsF.shape)\n",
    "    #print(outputsB.shape)\n",
    "    #print(events.shape)\n",
    "\n",
    "    norm = utils.compute_gradient_norm(model.parameters())\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    if enable_logging:\n",
    "            writer.add_scalar('model/loss', loss.item(), iteration)\n",
    "            writer.add_scalar('model/norm', norm.item(), iteration)\n",
    "\n",
    "    if iteration % 5 == 0:\n",
    "         save_model(model, optimizer, model_config, 'save/tempA.sess')\n",
    "\n",
    "    print(f'iter {iteration}, loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = None\n",
    "control = 'NONE'\n",
    "\n",
    "max_len = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'init_dim': max_len,\n",
    "    'event_dim': event_dim,\n",
    "    'control_dim': control_dim,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'gru_layers': gru_layers,\n",
    "    'gru_dropout': gru_droput,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load('save/tempA.sess', map_location=device)\n",
    "model = PerformanceRNN(**state['model_config']).to(device)\n",
    "model.load_state_dict(state['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceRNN(\n",
       "  (inithid_fc): Linear(in_features=32, out_features=1536, bias=True)\n",
       "  (inithid_fc_activation): Tanh()\n",
       "  (event_embedding): Embedding(240, 240)\n",
       "  (concat_input_fc): Linear(in_features=265, out_features=512, bias=True)\n",
       "  (concat_input_fc_activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  (gru): GRU(512, 512, num_layers=3, dropout=0.3)\n",
       "  (output_fc): Linear(in_features=1536, out_features=240, bias=True)\n",
       "  (output_fc_activation): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputF = []\n",
    "old = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.generate(init,max_len, controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.cpu().numpy().T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50, 197,  48, ..., 197,  48, 197],\n",
       "       [ 53, 192, 192, ..., 192, 192, 192],\n",
       "       [ 53, 203, 203, ..., 203, 203, 203],\n",
       "       ...,\n",
       "       [207, 207, 207, ..., 207, 207, 207],\n",
       "       [ 53, 207, 207, ..., 207, 207, 207],\n",
       "       [ 46,  46, 222, ...,  48, 197,  48]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    batch_gen = dataset.batches(batch_size, window_size, stride_size)\n",
    "    for iteration, data in enumerate(batch_gen):\n",
    "        e1 = data[0]\n",
    "        c1 = data[1]\n",
    "        e2 = data[2]\n",
    "        c2 = data[3]\n",
    "\n",
    "        # First Model process\n",
    "        max_len = c1.shape[0]\n",
    "\n",
    "        events = torch.LongTensor(e1).to(device)\n",
    "        assert events.shape[0] == window_size\n",
    "        assert len(events.shape) == 2\n",
    "        assert events.shape[0] >= window_size - 1\n",
    "\n",
    "        if np.random.random() < control_ratio:\n",
    "            controls = torch.FloatTensor(c1).to(device)\n",
    "            assert controls.shape[0] == window_size\n",
    "        else:\n",
    "            controls = None\n",
    "\n",
    "        init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "        outputs = model.generate(init,max_len, \n",
    "                                events[:-1], controls)\n",
    "        \n",
    "        assert outputs.shape[:2] == events.shape[:2]\n",
    "        #print(outputs)\n",
    "\n",
    "        # Second Model process\n",
    "\n",
    "        eventsB = torch.LongTensor(e2).to(device)\n",
    "        assert eventsB.shape[0] == window_size\n",
    "        assert len(eventsB.shape) == 2\n",
    "        assert eventsB.shape[0] >= window_size - 1\n",
    "\n",
    "        if np.random.random() < control_ratio:\n",
    "            controls = torch.FloatTensor(c2).to(device)\n",
    "            assert controls.shape[0] == window_size\n",
    "        else:\n",
    "            controls = None\n",
    "\n",
    "        init = torch.randn(batch_size, model2.init_dim).to(device)\n",
    "        outputsB = model2.generate(init, max_len, \n",
    "                                events=eventsB[:-1], events2=outputs[:-1], controls=controls,\n",
    "                                output_type='index')\n",
    "        outputF.append([outputsB, events])\n",
    "        old.append(outputs)\n",
    "        if iteration == 50:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = old[0].cpu().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.033329  , -3.0852256 , -2.9709718 , ..., -2.6993012 ,\n",
       "         -2.7076375 , -2.7189739 ],\n",
       "        [-2.7676702 , -2.940926  , -2.876566  , ..., -2.7019038 ,\n",
       "         -2.6886117 , -2.6757598 ],\n",
       "        [-2.8451457 , -2.9187024 , -2.854751  , ..., -2.7001088 ,\n",
       "         -2.7084332 , -2.7197595 ],\n",
       "        ...,\n",
       "        [-2.4381003 , -2.566773  , -2.5372918 , ..., -2.651637  ,\n",
       "         -2.6424255 , -2.6344972 ],\n",
       "        [-3.2426212 , -3.1992981 , -3.0019915 , ..., -2.6715646 ,\n",
       "         -2.6597784 , -2.6492589 ],\n",
       "        [-2.4098597 , -2.4663043 , -2.4977996 , ..., -2.6990337 ,\n",
       "         -2.7073605 , -2.7186904 ]],\n",
       "\n",
       "       [[-3.2805376 , -3.2945604 , -3.1769314 , ..., -2.9629111 ,\n",
       "         -2.9700105 , -2.9842064 ],\n",
       "        [-2.637222  , -2.9386058 , -2.9709218 , ..., -2.9761665 ,\n",
       "         -2.964363  , -2.9525466 ],\n",
       "        [-2.9294026 , -3.0802238 , -3.0566714 , ..., -2.9650445 ,\n",
       "         -2.972115  , -2.9862797 ],\n",
       "        ...,\n",
       "        [-2.4925306 , -2.6304078 , -2.6430595 , ..., -2.9317849 ,\n",
       "         -2.9229186 , -2.9152427 ],\n",
       "        [-3.400023  , -3.4443073 , -3.2846246 , ..., -2.9511597 ,\n",
       "         -2.9400623 , -2.9300196 ],\n",
       "        [-2.2453327 , -2.441462  , -2.5629647 , ..., -2.9616036 ,\n",
       "         -2.9687114 , -2.98291   ]],\n",
       "\n",
       "       [[-2.989554  , -3.118475  , -3.0411992 , ..., -2.8146033 ,\n",
       "         -2.8234725 , -2.844744  ],\n",
       "        [-3.2166107 , -3.2413914 , -3.0962906 , ..., -2.8712423 ,\n",
       "         -2.8660703 , -2.8595319 ],\n",
       "        [-2.858168  , -3.005515  , -2.962116  , ..., -2.8155284 ,\n",
       "         -2.824382  , -2.8456402 ],\n",
       "        ...,\n",
       "        [-2.760506  , -2.7676227 , -2.683408  , ..., -2.845374  ,\n",
       "         -2.8388076 , -2.8328066 ],\n",
       "        [-3.560764  , -3.4395397 , -3.1924844 , ..., -2.858949  ,\n",
       "         -2.851937  , -2.8449867 ],\n",
       "        [-2.805008  , -2.7682207 , -2.6850448 , ..., -2.8146658 ,\n",
       "         -2.8235316 , -2.844797  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0316882 , -1.1415383 , -1.1279951 , ..., -1.0612712 ,\n",
       "         -1.0673774 , -1.0730124 ],\n",
       "        [-1.0809128 , -1.1853029 , -1.174818  , ..., -1.0723076 ,\n",
       "         -1.0695035 , -1.0664347 ],\n",
       "        [-1.104993  , -1.1578686 , -1.1309435 , ..., -1.0606147 ,\n",
       "         -1.0667334 , -1.0723771 ],\n",
       "        ...,\n",
       "        [-1.0976253 , -1.082453  , -1.025145  , ..., -1.0600227 ,\n",
       "         -1.057261  , -1.0547603 ],\n",
       "        [-1.3837315 , -1.3085209 , -1.1975281 , ..., -1.0669825 ,\n",
       "         -1.06389   , -1.060915  ],\n",
       "        [-1.1652706 , -1.1232312 , -1.0734352 , ..., -1.0616739 ,\n",
       "         -1.0677764 , -1.0734047 ]],\n",
       "\n",
       "       [[-1.6179656 , -1.6947236 , -1.6568815 , ..., -1.498     ,\n",
       "         -1.5196021 , -1.5336369 ],\n",
       "        [-1.5468723 , -1.6270311 , -1.5888116 , ..., -1.527335  ,\n",
       "         -1.5193748 , -1.5116992 ],\n",
       "        [-1.3737373 , -1.5100048 , -1.5279479 , ..., -1.4979234 ,\n",
       "         -1.5195311 , -1.5335709 ],\n",
       "        ...,\n",
       "        [-1.5042987 , -1.5114973 , -1.4722362 , ..., -1.4981663 ,\n",
       "         -1.4927822 , -1.488199  ],\n",
       "        [-1.8982742 , -1.8073486 , -1.6698109 , ..., -1.5096465 ,\n",
       "         -1.5026388 , -1.4964298 ],\n",
       "        [-1.4020627 , -1.408889  , -1.4004047 , ..., -1.4975507 ,\n",
       "         -1.5191469 , -1.5331796 ]],\n",
       "\n",
       "       [[ 0.06614346,  0.11213538,  0.11787647, ...,  0.16097544,\n",
       "          0.16398296,  0.16326855],\n",
       "        [ 0.12709147,  0.09072798,  0.07786193, ...,  0.1387003 ,\n",
       "          0.13280474,  0.12748091],\n",
       "        [ 0.37370452,  0.30212405,  0.25552496, ...,  0.1626957 ,\n",
       "          0.16567387,  0.16493209],\n",
       "        ...,\n",
       "        [-0.26077014, -0.16315046, -0.10071333, ...,  0.11747554,\n",
       "          0.11405686,  0.11117881],\n",
       "        [ 0.12307724,  0.16046505,  0.15939194, ...,  0.12826191,\n",
       "          0.12359539,  0.11957169],\n",
       "        [-0.21254891, -0.08904321,  0.0075634 , ...,  0.16287132,\n",
       "          0.16587345,  0.16515028]]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event:\n",
    "\n",
    "    def __init__(self, type, time, value):\n",
    "        self.type = type\n",
    "        self.time = time\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Event(type={}, time={}, value={})'.format(\n",
    "            self.type, self.time, self.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_array(event_indeces):\n",
    "    time = 0\n",
    "    events = []\n",
    "    for event_index in event_indeces:\n",
    "        for event_type, feat_range in es.feat_ranges().items():\n",
    "            if (feat_range.start <= event_index) < feat_range.stop:\n",
    "                event_value = event_index - feat_range.start\n",
    "                events.append(Event(event_type, time, event_value))\n",
    "                if event_type == 'time_shift':\n",
    "                    time += es.time_shift_bins[event_value]\n",
    "                break\n",
    "\n",
    "    print(events)\n",
    "\n",
    "    return es(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SAVING_PROGRAM = 1\n",
    "DEFAULT_LOADING_PROGRAMS = range(128)\n",
    "DEFAULT_RESOLUTION = 220\n",
    "DEFAULT_TEMPO = 120\n",
    "DEFAULT_VELOCITY = 64\n",
    "DEFAULT_PITCH_RANGE = range(21, 109)\n",
    "DEFAULT_VELOCITY_RANGE = range(21, 109)\n",
    "DEFAULT_NORMALIZATION_BASELINE = 60  # C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_VELOCITY = True\n",
    "BEAT_LENGTH = 60 / DEFAULT_TEMPO\n",
    "DEFAULT_TIME_SHIFT_BINS = 1.15 ** np.arange(32) / 65\n",
    "DEFAULT_VELOCITY_STEPS = 32\n",
    "DEFAULT_NOTE_LENGTH = BEAT_LENGTH * 2\n",
    "MIN_NOTE_LENGTH = BEAT_LENGTH / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_note_seq(events):\n",
    "    time = 0\n",
    "    notes = []\n",
    "\n",
    "    velocity = DEFAULT_VELOCITY\n",
    "    velocity_bins = es.get_velocity_bins()\n",
    "\n",
    "    last_notes = {}\n",
    "\n",
    "    print(events)\n",
    "\n",
    "    for event in events:\n",
    "        if event.type == 'note_on':\n",
    "            pitch = event.value + es.pitch_range.start\n",
    "            note = Note(velocity, pitch, time, None)\n",
    "            notes.append(note)\n",
    "            last_notes[pitch] = note\n",
    "\n",
    "        elif event.type == 'note_off':\n",
    "            pitch = event.value + es.pitch_range.start\n",
    "\n",
    "            if pitch in last_notes:\n",
    "                note = last_notes[pitch]\n",
    "                note.end = max(time, note.start + MIN_NOTE_LENGTH)\n",
    "                del last_notes[pitch]\n",
    "\n",
    "        elif event.type == 'velocity':\n",
    "            index = min(event.value, velocity_bins.size - 1)\n",
    "            velocity = velocity_bins[index]\n",
    "\n",
    "        elif event.type == 'time_shift':\n",
    "            time += es.time_shift_bins[event.value]\n",
    "\n",
    "    for note in notes:\n",
    "        if note.end is None:\n",
    "            note.end = note.start + DEFAULT_NOTE_LENGTH\n",
    "\n",
    "        note.velocity = int(note.velocity)\n",
    "\n",
    "    return ns(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.13601229e-04 1.20252291e-04 2.39152669e-05 ... 4.50986045e-06\n",
      "   2.89303589e-05 2.58752425e-06]\n",
      "  [1.06278727e-04 2.20269021e-06 1.26815185e-05 ... 2.00609811e-05\n",
      "   6.55290060e-05 2.45055198e-05]\n",
      "  [1.54919588e-04 8.30569261e-05 4.96174725e-05 ... 8.20196510e-05\n",
      "   6.82196041e-05 6.37302510e-05]\n",
      "  ...\n",
      "  [9.87264357e-05 2.83538247e-06 1.13704518e-04 ... 3.17189770e-05\n",
      "   4.24269456e-06 1.49969674e-05]\n",
      "  [1.06813059e-04 4.25334692e-05 2.05532524e-05 ... 4.50605075e-05\n",
      "   3.19493483e-05 2.19254889e-05]\n",
      "  [9.12944306e-05 2.62257163e-06 1.20948229e-04 ... 1.19153128e-05\n",
      "   1.30850267e-05 1.19445132e-04]]\n",
      "\n",
      " [[2.70751305e-04 9.92179848e-05 2.18342375e-05 ... 9.65514482e-06\n",
      "   3.74713272e-05 6.27170903e-06]\n",
      "  [2.34336243e-04 6.56342490e-06 1.61588468e-05 ... 2.58053551e-05\n",
      "   7.41890763e-05 3.48760332e-05]\n",
      "  [2.29328143e-04 5.17725202e-05 4.37416420e-05 ... 4.32448614e-05\n",
      "   4.54655165e-05 3.98923112e-05]\n",
      "  ...\n",
      "  [2.23968862e-04 7.46548812e-06 1.24028986e-04 ... 3.45237058e-05\n",
      "   9.71635745e-06 1.55766302e-05]\n",
      "  [1.67415972e-04 2.92045734e-05 1.49096777e-05 ... 2.89759719e-05\n",
      "   2.11959978e-05 2.57308984e-05]\n",
      "  [1.68328450e-04 6.11251971e-06 1.10039320e-04 ... 1.67553735e-05\n",
      "   1.11098116e-05 1.13177935e-04]]\n",
      "\n",
      " [[1.27841718e-04 9.26608482e-05 1.53355031e-05 ... 4.57270107e-06\n",
      "   2.30148871e-05 3.11719373e-06]\n",
      "  [1.25703649e-04 3.50603568e-06 1.26341029e-05 ... 1.64429912e-05\n",
      "   6.19794955e-05 2.41546259e-05]\n",
      "  [1.74967267e-04 6.42082377e-05 4.32990855e-05 ... 6.49161229e-05\n",
      "   5.29760546e-05 4.75762135e-05]\n",
      "  ...\n",
      "  [6.63240644e-05 2.33704714e-06 4.82034775e-05 ... 1.45487593e-05\n",
      "   3.66081258e-06 7.66293033e-06]\n",
      "  [1.10784706e-04 3.08187409e-05 1.50329670e-05 ... 3.40735678e-05\n",
      "   2.33877308e-05 1.87563965e-05]\n",
      "  [9.76870142e-05 3.54438885e-06 8.28596530e-05 ... 1.40693037e-05\n",
      "   9.43870600e-06 1.12368849e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.77802667e-03 4.57633316e-04 1.07029053e-04 ... 2.78591970e-03\n",
      "   4.81523784e-05 5.73470723e-03]\n",
      "  [3.34953982e-03 3.96439852e-03 2.01837138e-05 ... 3.01588298e-04\n",
      "   9.71624919e-04 4.45764417e-05]\n",
      "  [3.10828513e-03 9.59275872e-04 3.11414660e-05 ... 7.85447701e-05\n",
      "   8.47864663e-04 8.49948672e-04]\n",
      "  ...\n",
      "  [2.43810355e-03 2.22680322e-03 4.76547029e-05 ... 4.18716227e-05\n",
      "   5.39893983e-03 1.70475669e-05]\n",
      "  [2.84487894e-03 2.24485208e-04 9.92729911e-05 ... 2.61491281e-04\n",
      "   1.94857712e-04 3.86477695e-05]\n",
      "  [2.90658465e-03 4.54612030e-03 7.64837096e-05 ... 6.86261291e-03\n",
      "   3.40425759e-05 2.10509496e-03]]\n",
      "\n",
      " [[2.54390435e-03 3.99895362e-04 1.01059035e-04 ... 8.04074225e-04\n",
      "   5.90234122e-05 1.26192183e-03]\n",
      "  [1.83457008e-03 8.17792490e-04 2.51049314e-05 ... 1.89102619e-04\n",
      "   6.08522445e-04 4.39942123e-05]\n",
      "  [2.24270648e-03 6.52091345e-04 4.56643720e-05 ... 8.01523056e-05\n",
      "   5.51638950e-04 5.30078541e-04]\n",
      "  ...\n",
      "  [1.70632685e-03 7.04659789e-04 6.24268650e-05 ... 4.10637113e-05\n",
      "   1.50422892e-03 2.21246410e-05]\n",
      "  [2.31280690e-03 2.12016617e-04 1.03245649e-04 ... 2.48589349e-04\n",
      "   1.92413791e-04 4.86372119e-05]\n",
      "  [2.17896793e-03 9.76684853e-04 1.15153329e-04 ... 2.09556730e-03\n",
      "   3.45660410e-05 1.42478524e-03]]\n",
      "\n",
      " [[1.45755289e-02 6.38874713e-04 1.17181524e-04 ... 2.09141895e-03\n",
      "   1.91722880e-04 5.63100446e-03]\n",
      "  [1.19514531e-02 2.56669801e-03 3.78480909e-05 ... 3.51440307e-04\n",
      "   1.76423613e-03 1.95310582e-04]\n",
      "  [1.62579492e-02 3.81871895e-03 1.12534653e-04 ... 9.00282394e-05\n",
      "   1.25796464e-03 1.70037639e-03]\n",
      "  ...\n",
      "  [1.29464641e-02 1.81650545e-03 1.13635084e-04 ... 1.83421362e-04\n",
      "   8.44722614e-03 3.21742373e-05]\n",
      "  [1.33509859e-02 1.92782725e-04 1.07611682e-04 ... 2.69633980e-04\n",
      "   1.88598700e-04 1.55884700e-04]\n",
      "  [1.59463901e-02 4.05860506e-03 2.18576097e-04 ... 3.04279383e-02\n",
      "   3.04158984e-05 4.36564814e-03]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(arr)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#for i, output in enumerate(itemS):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#    name = f'output-{i:03d}.mid'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#    print(name)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#    print(type(output))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#    es1 = from_array(output)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m es1 \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m ns \u001b[38;5;241m=\u001b[39m to_note_seq(es1)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(ns)\n",
      "File \u001b[0;32m~/Documents/GitHub/TesiFinal/Utils/EventSeq.py:94\u001b[0m, in \u001b[0;36mEventSeq.from_array\u001b[0;34m(event_indeces)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event_index \u001b[38;5;129;01min\u001b[39;00m event_indeces:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event_type, feat_range \u001b[38;5;129;01min\u001b[39;00m EventSeq\u001b[38;5;241m.\u001b[39mfeat_ranges()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m feat_range\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m event_index \u001b[38;5;241m<\u001b[39m feat_range\u001b[38;5;241m.\u001b[39mstop:\n\u001b[1;32m     95\u001b[0m             event_value \u001b[38;5;241m=\u001b[39m event_index \u001b[38;5;241m-\u001b[39m feat_range\u001b[38;5;241m.\u001b[39mstart\n\u001b[1;32m     96\u001b[0m             events\u001b[38;5;241m.\u001b[39mappend(Event(event_type, time, event_value))\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "for processed, inputstream in outputF:\n",
    "    itemS = processed.cpu().numpy().T\n",
    "\n",
    "    arr = np.stack(itemS)\n",
    "    print(arr)\n",
    "\n",
    "    #for i, output in enumerate(itemS):\n",
    "    #    name = f'output-{i:03d}.mid'\n",
    "    #    print(name)\n",
    "    #    print(type(output))\n",
    "    #    es1 = from_array(output)\n",
    "\n",
    "    es1 = es.from_array(itemS)\n",
    "    ns = to_note_seq(es1)\n",
    "    print(ns)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bagigi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
